{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project 3. InfoExplorers."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e42b070e34804c0e"
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:46.574502Z",
     "start_time": "2023-12-17T18:51:46.503635Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "import networkx as nx\n",
    "import heapq\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data loading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0751a99dd67d9a7"
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "# Constant paths\n",
    "DATA_FOLDER = 'data/'\n",
    "PICKLES_FOLDER = 'pickles/'\n",
    "WIKILITE_FOLDER = DATA_FOLDER + 'wiki_lite/'\n",
    "SUBMISSIONS_FOLDER = 'submissions/'\n",
    "CORRECTED_FOLDER = 'corrected/'\n",
    "\n",
    "# Create folders if they don't exist\n",
    "if not os.path.exists(PICKLES_FOLDER):\n",
    "    os.makedirs(PICKLES_FOLDER)\n",
    "\n",
    "if not os.path.exists(SUBMISSIONS_FOLDER):\n",
    "    os.makedirs(SUBMISSIONS_FOLDER)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:46.585462Z",
     "start_time": "2023-12-17T18:51:46.509290Z"
    }
   },
   "id": "18f1bb4a3fc83cd6"
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "# Train data loading\n",
    "try:\n",
    "    train_df = pd.read_pickle(PICKLES_FOLDER + 'train_df.pkl')\n",
    "except:\n",
    "    train_df = pd.read_csv(DATA_FOLDER + 'train.csv')\n",
    "    train_df.to_pickle(PICKLES_FOLDER + 'train_df.pkl')\n",
    "\n",
    "# Test data loading  \n",
    "try:\n",
    "    test_df = pd.read_pickle(PICKLES_FOLDER + 'test_df.pkl')\n",
    "except:\n",
    "    test_df = pd.read_csv(DATA_FOLDER + 'test.csv')\n",
    "    test_df.to_pickle(PICKLES_FOLDER + 'test_df.pkl')\n",
    "\n",
    "# Redirects loading\n",
    "try:\n",
    "    enwinki_redirects = pd.read_pickle(PICKLES_FOLDER + 'enwiki_redirects.pkl')\n",
    "except:\n",
    "    enwinki_redirects = pd.read_csv(WIKILITE_FOLDER + 'enwiki_redirects.tsv', names=['en_title', 'en_redirect_title'],\n",
    "                                    sep='\\t')\n",
    "    enwinki_redirects.to_pickle(PICKLES_FOLDER + 'enwiki_redirects.pkl')\n",
    "\n",
    "# Aliases loading  \n",
    "try:\n",
    "    item_aliases = pd.read_pickle(PICKLES_FOLDER + 'item_aliases.pkl')\n",
    "except:\n",
    "    item_aliases = pd.read_csv(WIKILITE_FOLDER + 'item_aliases.csv')\n",
    "    item_aliases.to_pickle(PICKLES_FOLDER + 'item_aliases.pkl')\n",
    "\n",
    "# Properties loading\n",
    "try:\n",
    "    properties = pd.read_pickle(PICKLES_FOLDER + 'property.pkl')\n",
    "except:\n",
    "    properties = pd.read_csv(WIKILITE_FOLDER + 'property.csv')\n",
    "    properties.to_pickle(PICKLES_FOLDER + 'property.pkl')\n",
    "\n",
    "# Statements loading\n",
    "try:\n",
    "    statements = pd.read_pickle(PICKLES_FOLDER + 'statements.pkl')\n",
    "except:\n",
    "    statements = pd.read_csv(WIKILITE_FOLDER + 'statements.csv')\n",
    "    statements.to_pickle(PICKLES_FOLDER + 'statements.pkl')\n",
    "\n",
    "# Wiki items loading \n",
    "try:\n",
    "    wiki_items = pd.read_pickle(PICKLES_FOLDER + 'wiki_items.pkl')\n",
    "except:\n",
    "    wiki_items = pd.read_csv(WIKILITE_FOLDER + 'wiki_items.csv')\n",
    "    wiki_items.to_pickle(PICKLES_FOLDER + 'wiki_items.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:49.185545Z",
     "start_time": "2023-12-17T18:51:46.515507Z"
    }
   },
   "id": "8b9e6f0ee2813fe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1: Using existing datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74aa5a0e772b9c9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78f73f63d272f417"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Merging `item_aliases` and `wiki_items` on `item_id` to get the `wikipedia_title` for each `en_alias`:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b64eefea3ce0942"
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "data": {
      "text/plain": "   item_id  en_label                                 en_description  \\\n0        1  Universe             totality of space and all contents   \n1        1  Universe             totality of space and all contents   \n2        1  Universe             totality of space and all contents   \n3        1  Universe             totality of space and all contents   \n4        2     Earth  third planet from the Sun in the Solar System   \n\n  wikipedia_title      en_alias  \n0        Universe  Our Universe  \n1        Universe  The Universe  \n2        Universe    The Cosmos  \n3        Universe        cosmos  \n4           Earth   Blue Planet  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_id</th>\n      <th>en_label</th>\n      <th>en_description</th>\n      <th>wikipedia_title</th>\n      <th>en_alias</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Universe</td>\n      <td>totality of space and all contents</td>\n      <td>Universe</td>\n      <td>Our Universe</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Universe</td>\n      <td>totality of space and all contents</td>\n      <td>Universe</td>\n      <td>The Universe</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Universe</td>\n      <td>totality of space and all contents</td>\n      <td>Universe</td>\n      <td>The Cosmos</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Universe</td>\n      <td>totality of space and all contents</td>\n      <td>Universe</td>\n      <td>cosmos</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Earth</td>\n      <td>third planet from the Sun in the Solar System</td>\n      <td>Earth</td>\n      <td>Blue Planet</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_wiki_items = wiki_items.merge(item_aliases, how='left', on='item_id')\n",
    "merged_wiki_items.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:50.350315Z",
     "start_time": "2023-12-17T18:51:49.186555Z"
    }
   },
   "id": "bd280c1982f55afb"
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "# Copying the dataframes to modify them\n",
    "test_df_mod = test_df.copy(deep=True)\n",
    "train_df_mod = train_df.copy(deep=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:50.360661Z",
     "start_time": "2023-12-17T18:51:50.349976Z"
    }
   },
   "id": "82965c83ebbb3015"
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "# Beginning of the URL to wikipedia\n",
    "URL = 'http://en.wikipedia.org/wiki/'\n",
    "LEN_URL = len(URL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:50.367489Z",
     "start_time": "2023-12-17T18:51:50.361874Z"
    }
   },
   "id": "2cb2450d10518b95"
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "# We need to lowercase the tokens to avoid problems with case in future steps\n",
    "train_df_mod['full_mention_lower'] = train_df_mod['full_mention'].str.lower()\n",
    "\n",
    "# We only keep the tokens that have a wiki_url\n",
    "train_df_mod = train_df_mod[train_df_mod['wiki_url'].notnull() & (train_df_mod['wiki_url'] != '--NME--')]\n",
    "\n",
    "# We also lowercase the tokens in the test data for future steps\n",
    "test_df_mod['full_mention'] = test_df_mod['full_mention'].str.lower()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:50.419322Z",
     "start_time": "2023-12-17T18:51:50.373533Z"
    }
   },
   "id": "7249692acea2e0eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We transform:\n",
    "- `en_alias` and `wikipedia_title` in `merged_wiki_items`\n",
    "- `wikipedia_title` in `wiki_items`\n",
    "- `en_title` in `redirects`\n",
    "\n",
    "to lowercase to avoid problems with case in future steps"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd5f505f0444795b"
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "merged_wiki_items['en_alias_lower'] = merged_wiki_items['en_alias'].str.lower()\n",
    "merged_wiki_items['wikipedia_title_lower'] = merged_wiki_items['wikipedia_title'].str.lower()\n",
    "\n",
    "wiki_items['wikipedia_title_lower'] = wiki_items['wikipedia_title'].str.lower()\n",
    "\n",
    "enwinki_redirects['en_title_lower'] = enwinki_redirects['en_title'].str.lower()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:52.700892Z",
     "start_time": "2023-12-17T18:51:50.501628Z"
    }
   },
   "id": "7d96a359b740d910"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating dictionaries for faster lookup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef8e3b286066879e"
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "DICT_FOLDER = PICKLES_FOLDER + 'dictionaries/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:52.703329Z",
     "start_time": "2023-12-17T18:51:52.701611Z"
    }
   },
   "id": "cf3e7bcd5309c070"
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "try:\n",
    "    aliases_dict = pickle.load(open(DICT_FOLDER + 'aliases_dict.pkl', 'rb'))\n",
    "except:\n",
    "    aliases_dict = pd.Series(merged_wiki_items['wikipedia_title'].values,\n",
    "                             index=merged_wiki_items['en_alias_lower']).to_dict()\n",
    "    pickle.dump(aliases_dict, open(DICT_FOLDER + 'aliases_dict.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:53.147673Z",
     "start_time": "2023-12-17T18:51:52.704119Z"
    }
   },
   "id": "82d4af9957872fe7"
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "try:\n",
    "    titles_dict = pickle.load(open(DICT_FOLDER + 'titles_dict.pkl', 'rb'))\n",
    "except:\n",
    "    titles_dict = pd.Series(wiki_items['wikipedia_title'].values, index=wiki_items['wikipedia_title_lower']).to_dict()\n",
    "    pickle.dump(titles_dict, open(DICT_FOLDER + 'titles_dict.pkl', 'wb'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:54.892943Z",
     "start_time": "2023-12-17T18:51:53.145092Z"
    }
   },
   "id": "e2a837f701077025"
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "try:\n",
    "    train_dict = pickle.load(open(DICT_FOLDER + 'train_dict.pkl', 'rb'))\n",
    "except:\n",
    "    train_dict = pd.Series(train_df_mod['wiki_url'].values, index=train_df_mod['full_mention_lower']).to_dict()\n",
    "    pickle.dump(train_dict, open(DICT_FOLDER + 'train_dict.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:54.899937Z",
     "start_time": "2023-12-17T18:51:54.894259Z"
    }
   },
   "id": "d6c486944ee1036d"
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "try:\n",
    "    redirects_dict = pickle.load(open(DICT_FOLDER + 'redirects_dict.pkl', 'rb'))\n",
    "except:\n",
    "    redirects_dict = pd.Series(enwinki_redirects['en_redirect_title'].values,\n",
    "                               index=enwinki_redirects['en_title_lower']).to_dict()\n",
    "    pickle.dump(redirects_dict, open(DICT_FOLDER + 'redirects_dict.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:57.410472Z",
     "start_time": "2023-12-17T18:51:54.899515Z"
    }
   },
   "id": "252ec3cd41695de4"
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104890/104890 [00:01<00:00, 61111.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# We want to keep the count of the number of matches we find with aliases and redirects\n",
    "aliases_matching = 0\n",
    "redirects_matching = 0\n",
    "\n",
    "for index, row in tqdm(test_df_mod.iterrows(), total=test_df_mod.shape[0]):\n",
    "    if str(row['wiki_url']) == 'nan' or row['wiki_url'] != '?':\n",
    "        continue\n",
    "\n",
    "    token = row['full_mention']\n",
    "    train_url = train_dict.get(token)\n",
    "\n",
    "    if train_url is not None:\n",
    "        # We found a link in the train data and it is the true identity so we can use it\n",
    "        test_df_mod.at[index, 'wiki_url'] = train_url\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        # TODO: explain the order of the if statements in the report\n",
    "        wiki_title = titles_dict.get(token)\n",
    "\n",
    "        if wiki_title is not None:\n",
    "            aliases_matching += 1\n",
    "\n",
    "        else:\n",
    "            wiki_title = aliases_dict.get(token)\n",
    "\n",
    "            if wiki_title is not None:\n",
    "                aliases_matching += 1\n",
    "\n",
    "    if wiki_title is not None:\n",
    "        redirect_title = redirects_dict.get(wiki_title.lower())\n",
    "\n",
    "        if redirect_title is not None:\n",
    "            redirects_matching += 1\n",
    "            test_df_mod.at[index, 'wiki_url'] = URL + redirect_title.replace(' ', '_')\n",
    "\n",
    "        else:\n",
    "            test_df_mod.at[index, 'wiki_url'] = URL + wiki_title.replace(' ', '_')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:59.133475Z",
     "start_time": "2023-12-17T18:51:57.414528Z"
    }
   },
   "id": "8e186a6eee7eb6ba"
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "data": {
      "text/plain": "2107"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aliases_matching"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:59.137928Z",
     "start_time": "2023-12-17T18:51:59.134268Z"
    }
   },
   "id": "416956ed3cbe7456"
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "data": {
      "text/plain": "393"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redirects_matching"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:59.144974Z",
     "start_time": "2023-12-17T18:51:59.136932Z"
    }
   },
   "id": "38d44acc9170b212"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see how many tokens we found links for:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7507b3a85b5a8586"
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously we had 9166 tokens without a link\n",
      "Now we have 547 tokens without a link\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previously we had {test_df[test_df['wiki_url'] == '?']['wiki_url'].count()} tokens without a link\")\n",
    "print(f\"Now we have {test_df_mod[test_df_mod['wiki_url'] == '?']['wiki_url'].count()} tokens without a link\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:59.147303Z",
     "start_time": "2023-12-17T18:51:59.140506Z"
    }
   },
   "id": "c3e735d9fe28d308"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating submission file for second part"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2f5746f1b4d3123"
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "result_first_part = test_df_mod[['id', 'wiki_url']]\n",
    "result_first_part.loc[:, 'wiki_url'] = result_first_part['wiki_url'].apply(lambda x: 'NOT_FOUND' if not (str(x).startswith('http') or str(x) == '?') else x)\n",
    "# result_first_part.loc[:, 'wiki_url'] = result_first_part['wiki_url'].apply(lambda x: 'NOT_FOUND' if not (str(x).startswith('http')) else x)\n",
    "\n",
    "# name = 'tr_title_alias_dict_redirects_url'\n",
    "# \n",
    "# result_first_part.to_csv(SUBMISSIONS_FOLDER + name + '.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:59.190398Z",
     "start_time": "2023-12-17T18:51:59.173614Z"
    }
   },
   "id": "df485ff6287f478b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2: Knowledge Graph"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f374ebae8b86d158"
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "def get_connection(only_train=False):\n",
    "    \"\"\"\n",
    "    Function retrieving the connection between the wiki_items from the statements.csv file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    only_train: bool, optional (default=False)\n",
    "        If True, only the connections between the items in the train data are returned.\n",
    "    \n",
    "    Returns\n",
    "    -------  \n",
    "    connection: pd.DataFrame\n",
    "        DataFrame containing the connections between the wiki_items.\n",
    "    \"\"\"\n",
    "    \n",
    "    connection = statements\n",
    "    if only_train:\n",
    "        list_of_ids = pd.read_csv('train_wiki.csv')  # obtain by running get_wiki.ipynb\n",
    "        list_of_ids = list_of_ids.item_id.tolist()\n",
    "        all_ids = set(connection['source_item_id'].unique()).union(set(connection['target_item_id'].unique()))\n",
    "\n",
    "        filtered_ids = set(list_of_ids).intersection(all_ids)\n",
    "\n",
    "        connection = connection[\n",
    "            connection['source_item_id'].isin(filtered_ids) | connection['target_item_id'].isin(filtered_ids)]\n",
    "    return connection\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:59.197777Z",
     "start_time": "2023-12-17T18:51:59.178360Z"
    }
   },
   "id": "f2d633317a1327cd"
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "def add_edges(G, connection, progress=True):\n",
    "    \"\"\"\n",
    "    Function adding the edges to the graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    G: nx.Graph\n",
    "        Graph to which the edges are added.\n",
    "    connection: pd.DataFrame\n",
    "        DataFrame containing the connections between the wiki_items.\n",
    "    progress: bool, optional (default=True)\n",
    "        If True, a progress bar is shown.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    G: nx.Graph\n",
    "        Graph with the added edges. \n",
    "    \"\"\"\n",
    "    \n",
    "    if progress:\n",
    "        for source_item_id, _, target_item_id in tqdm(connection.iloc, total=len(connection)):\n",
    "            G.add_edge(source_item_id, target_item_id)\n",
    "    else:\n",
    "        G = nx.from_pandas_edgelist(connection, 'source_item_id', 'target_item_id', create_using=nx.Graph)\n",
    "    return G"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:59.197953Z",
     "start_time": "2023-12-17T18:51:59.181416Z"
    }
   },
   "id": "e80f9d6941dae5d1"
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "PICKLE_FILENAME = \"graph_undirected_full.pkl\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:51:59.198015Z",
     "start_time": "2023-12-17T18:51:59.183385Z"
    }
   },
   "id": "4e5f0950aac4c8de"
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load the graph from the pickle file\n",
    "    with open(PICKLES_FOLDER + PICKLE_FILENAME, 'rb') as pickle_file:\n",
    "        G = pickle.load(pickle_file)\n",
    "except:\n",
    "    connection = get_connection()\n",
    "    G = nx.Graph()  # Undirected Graph\n",
    "    G = add_edges(G, connection, progress=True)\n",
    "    \n",
    "    # Save graph pickle to the file\n",
    "    with open(PICKLES_FOLDER + PICKLE_FILENAME, 'wb') as pickle_file:\n",
    "        pickle.dump(G, pickle_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:52:23.536334Z",
     "start_time": "2023-12-17T18:51:59.185997Z"
    }
   },
   "id": "6d20743712452f8e"
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 4906271\n",
      "Number of edges: 24528246\n"
     ]
    }
   ],
   "source": [
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "\n",
    "print(f\"Number of nodes: {num_nodes}\")\n",
    "print(f\"Number of edges: {num_edges}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:52:24.350181Z",
     "start_time": "2023-12-17T18:52:23.547419Z"
    }
   },
   "id": "789a31308f2cfcff"
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "data": {
      "text/plain": "            id                          token entity_tag    full_mention  \\\n0            0  -DOCSTART- (947testa CRICKET)        NaN             NaN   \n1            1                        CRICKET        NaN             NaN   \n2            2                              -        NaN             NaN   \n3            3                 LEICESTERSHIRE          B  LEICESTERSHIRE   \n4            4                           TAKE        NaN             NaN   \n...        ...                            ...        ...             ...   \n104885  104885                        brother        NaN             NaN   \n104886  104886                              ,        NaN             NaN   \n104887  104887                          Bobby          B           Bobby   \n104888  104888                              .        NaN             NaN   \n104889  104889                            NaN        NaN             NaN   \n\n       wiki_url_x                                         wiki_url_y  \n0             NaN                                          NOT_FOUND  \n1             NaN                                          NOT_FOUND  \n2             NaN                                          NOT_FOUND  \n3               ?  http://en.wikipedia.org/wiki/Leicestershire_Co...  \n4             NaN                                          NOT_FOUND  \n...           ...                                                ...  \n104885        NaN                                          NOT_FOUND  \n104886        NaN                                          NOT_FOUND  \n104887          ?                 http://en.wikipedia.org/wiki/Bobby  \n104888        NaN                                          NOT_FOUND  \n104889        NaN                                          NOT_FOUND  \n\n[104890 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>token</th>\n      <th>entity_tag</th>\n      <th>full_mention</th>\n      <th>wiki_url_x</th>\n      <th>wiki_url_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-DOCSTART- (947testa CRICKET)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>CRICKET</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>-</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>LEICESTERSHIRE</td>\n      <td>B</td>\n      <td>LEICESTERSHIRE</td>\n      <td>?</td>\n      <td>http://en.wikipedia.org/wiki/Leicestershire_Co...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>TAKE</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>104885</th>\n      <td>104885</td>\n      <td>brother</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n    </tr>\n    <tr>\n      <th>104886</th>\n      <td>104886</td>\n      <td>,</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n    </tr>\n    <tr>\n      <th>104887</th>\n      <td>104887</td>\n      <td>Bobby</td>\n      <td>B</td>\n      <td>Bobby</td>\n      <td>?</td>\n      <td>http://en.wikipedia.org/wiki/Bobby</td>\n    </tr>\n    <tr>\n      <th>104888</th>\n      <td>104888</td>\n      <td>.</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n    </tr>\n    <tr>\n      <th>104889</th>\n      <td>104889</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n    </tr>\n  </tbody>\n</table>\n<p>104890 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Taking the result from the first part\n",
    "partial = result_first_part\n",
    "\n",
    "testdf = test_df.copy(deep=True)\n",
    "testdf = testdf.merge(partial, on='id')\n",
    "display(testdf)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:52:24.398256Z",
     "start_time": "2023-12-17T18:52:24.350669Z"
    }
   },
   "id": "c74cc83c41c2746b"
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "data": {
      "text/plain": "         id                    en_redirect_title\n0       795   Universities in the United Kingdom\n1       975   Universities in the United Kingdom\n2      4396                           David Barr\n3      4402                     Michael Sullivan\n4      4552  United States Amateur Championships\n..      ...                                  ...\n342  103998                    Predrag Mijatović\n343  104041                    Predrag Mijatović\n344  104124                            Mijatović\n345  104310                        De Graafschap\n346  104877                  1966 FIFA World Cup\n\n[347 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>en_redirect_title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>795</td>\n      <td>Universities in the United Kingdom</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>975</td>\n      <td>Universities in the United Kingdom</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4396</td>\n      <td>David Barr</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4402</td>\n      <td>Michael Sullivan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4552</td>\n      <td>United States Amateur Championships</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>103998</td>\n      <td>Predrag Mijatović</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>104041</td>\n      <td>Predrag Mijatović</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>104124</td>\n      <td>Mijatović</td>\n    </tr>\n    <tr>\n      <th>345</th>\n      <td>104310</td>\n      <td>De Graafschap</td>\n    </tr>\n    <tr>\n      <th>346</th>\n      <td>104877</td>\n      <td>1966 FIFA World Cup</td>\n    </tr>\n  </tbody>\n</table>\n<p>347 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "redirect = enwinki_redirects\n",
    "temp = testdf[partial.wiki_url == \"?\"].merge(redirect, left_on='full_mention', right_on='en_title')[['id', 'en_redirect_title']]\n",
    "\n",
    "display(temp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:52:27.848835Z",
     "start_time": "2023-12-17T18:52:24.561400Z"
    }
   },
   "id": "6070da4a30bc3db4"
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "data": {
      "text/plain": "            id                          token entity_tag    full_mention  \\\n0            0  -DOCSTART- (947testa CRICKET)        NaN             NaN   \n1            1                        CRICKET        NaN             NaN   \n2            2                              -        NaN             NaN   \n3            3                 LEICESTERSHIRE          B  LEICESTERSHIRE   \n4            4                           TAKE        NaN             NaN   \n...        ...                            ...        ...             ...   \n104885  104885                        brother        NaN             NaN   \n104886  104886                              ,        NaN             NaN   \n104887  104887                          Bobby          B           Bobby   \n104888  104888                              .        NaN             NaN   \n104889  104889                            NaN        NaN             NaN   \n\n                                                 wiki_url en_redirect_title  \n0                                               NOT_FOUND               NaN  \n1                                               NOT_FOUND               NaN  \n2                                               NOT_FOUND               NaN  \n3       http://en.wikipedia.org/wiki/Leicestershire_Co...    LEICESTERSHIRE  \n4                                               NOT_FOUND               NaN  \n...                                                   ...               ...  \n104885                                          NOT_FOUND               NaN  \n104886                                          NOT_FOUND               NaN  \n104887                 http://en.wikipedia.org/wiki/Bobby             Bobby  \n104888                                          NOT_FOUND               NaN  \n104889                                          NOT_FOUND               NaN  \n\n[104890 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>token</th>\n      <th>entity_tag</th>\n      <th>full_mention</th>\n      <th>wiki_url</th>\n      <th>en_redirect_title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-DOCSTART- (947testa CRICKET)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>CRICKET</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>-</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>LEICESTERSHIRE</td>\n      <td>B</td>\n      <td>LEICESTERSHIRE</td>\n      <td>http://en.wikipedia.org/wiki/Leicestershire_Co...</td>\n      <td>LEICESTERSHIRE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>TAKE</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>104885</th>\n      <td>104885</td>\n      <td>brother</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>104886</th>\n      <td>104886</td>\n      <td>,</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>104887</th>\n      <td>104887</td>\n      <td>Bobby</td>\n      <td>B</td>\n      <td>Bobby</td>\n      <td>http://en.wikipedia.org/wiki/Bobby</td>\n      <td>Bobby</td>\n    </tr>\n    <tr>\n      <th>104888</th>\n      <td>104888</td>\n      <td>.</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>104889</th>\n      <td>104889</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>104890 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testdf = testdf.merge(temp, on='id', how='left')\n",
    "testdf['en_redirect_title'] = testdf.apply(lambda row: row.full_mention if pd.isna(row['en_redirect_title']) else row['en_redirect_title'], axis=1)\n",
    "\n",
    "testdf = testdf.drop(columns=['wiki_url_x'])\n",
    "testdf.rename(columns={'wiki_url_y': 'wiki_url'}, inplace=True)\n",
    "display(testdf)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:52:28.452996Z",
     "start_time": "2023-12-17T18:52:27.849023Z"
    }
   },
   "id": "4cd6d5c1e8498977"
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "data": {
      "text/plain": "          item_id                 en_label          wikipedia_title\n0               1                 Universe                 Universe\n1               2                    Earth                    Earth\n2               3                     life                     Life\n3               4                    death                    Death\n4               5                    human                    Human\n...           ...                      ...                      ...\n5216231  77042017                  HR 4523                HD 102365\n5216232  77043280         Charlie Johnston        Charlie Johnstone\n5216233  77231860               Aldo Rossi    Aldo Rossi (musician)\n5216234  77240068  Ebenezer Baptist Church  Ebenezer Baptist Church\n5216235  77242291                New Court                New Court\n\n[5216236 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_id</th>\n      <th>en_label</th>\n      <th>wikipedia_title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Universe</td>\n      <td>Universe</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Earth</td>\n      <td>Earth</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>life</td>\n      <td>Life</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>death</td>\n      <td>Death</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>human</td>\n      <td>Human</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5216231</th>\n      <td>77042017</td>\n      <td>HR 4523</td>\n      <td>HD 102365</td>\n    </tr>\n    <tr>\n      <th>5216232</th>\n      <td>77043280</td>\n      <td>Charlie Johnston</td>\n      <td>Charlie Johnstone</td>\n    </tr>\n    <tr>\n      <th>5216233</th>\n      <td>77231860</td>\n      <td>Aldo Rossi</td>\n      <td>Aldo Rossi (musician)</td>\n    </tr>\n    <tr>\n      <th>5216234</th>\n      <td>77240068</td>\n      <td>Ebenezer Baptist Church</td>\n      <td>Ebenezer Baptist Church</td>\n    </tr>\n    <tr>\n      <th>5216235</th>\n      <td>77242291</td>\n      <td>New Court</td>\n      <td>New Court</td>\n    </tr>\n  </tbody>\n</table>\n<p>5216236 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wiki_item = wiki_items[['item_id', 'en_label', 'wikipedia_title']]\n",
    "# wiki_item = wiki_item[wiki_item['item_id'].isin(filtered_ids)]\n",
    "\n",
    "# wiki_item['en_label'] = wiki_item['en_label'] + \" \" + wiki_item['wikipedia_title']\n",
    "col_ = wiki_item.wikipedia_title.str.lower().str\n",
    "lower_case_wiki_item_titles = wiki_item.wikipedia_title.str.lower().str\n",
    "display(wiki_item)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:52:29.822188Z",
     "start_time": "2023-12-17T18:52:28.468616Z"
    }
   },
   "id": "b7c7606df31d5ffe"
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "data": {
      "text/plain": "            id                          token entity_tag    full_mention  \\\n0            0  -DOCSTART- (947testa CRICKET)        NaN             NaN   \n1            1                        CRICKET        NaN             NaN   \n2            2                              -        NaN             NaN   \n3            3                 LEICESTERSHIRE          B  LEICESTERSHIRE   \n4            4                           TAKE        NaN             NaN   \n...        ...                            ...        ...             ...   \n104885  104885                        brother        NaN             NaN   \n104886  104886                              ,        NaN             NaN   \n104887  104887                          Bobby          B           Bobby   \n104888  104888                              .        NaN             NaN   \n104889  104889                            NaN        NaN             NaN   \n\n                                                 wiki_url en_redirect_title  \\\n0                                               NOT_FOUND               NaN   \n1                                               NOT_FOUND               NaN   \n2                                               NOT_FOUND               NaN   \n3       http://en.wikipedia.org/wiki/Leicestershire_Co...    LEICESTERSHIRE   \n4                                               NOT_FOUND               NaN   \n...                                                   ...               ...   \n104885                                          NOT_FOUND               NaN   \n104886                                          NOT_FOUND               NaN   \n104887                 http://en.wikipedia.org/wiki/Bobby             Bobby   \n104888                                          NOT_FOUND               NaN   \n104889                                          NOT_FOUND               NaN   \n\n          item_id  \n0             NaN  \n1             NaN  \n2             NaN  \n3       3229147.0  \n4             NaN  \n...           ...  \n104885        NaN  \n104886        NaN  \n104887   289262.0  \n104888        NaN  \n104889        NaN  \n\n[104890 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>token</th>\n      <th>entity_tag</th>\n      <th>full_mention</th>\n      <th>wiki_url</th>\n      <th>en_redirect_title</th>\n      <th>item_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-DOCSTART- (947testa CRICKET)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>CRICKET</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>-</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>LEICESTERSHIRE</td>\n      <td>B</td>\n      <td>LEICESTERSHIRE</td>\n      <td>http://en.wikipedia.org/wiki/Leicestershire_Co...</td>\n      <td>LEICESTERSHIRE</td>\n      <td>3229147.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>TAKE</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>104885</th>\n      <td>104885</td>\n      <td>brother</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>104886</th>\n      <td>104886</td>\n      <td>,</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>104887</th>\n      <td>104887</td>\n      <td>Bobby</td>\n      <td>B</td>\n      <td>Bobby</td>\n      <td>http://en.wikipedia.org/wiki/Bobby</td>\n      <td>Bobby</td>\n      <td>289262.0</td>\n    </tr>\n    <tr>\n      <th>104888</th>\n      <td>104888</td>\n      <td>.</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>104889</th>\n      <td>104889</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>104890 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testdf['wiki_title'] = testdf.wiki_url.str[LEN_URL:].str.replace('_', ' ')\n",
    "testdf = testdf.merge(wiki_item, left_on='wiki_title', right_on='wikipedia_title', how='left').drop(\n",
    "    columns=['wikipedia_title', 'en_label', 'wiki_title'])\n",
    "display(testdf)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:52:31.502314Z",
     "start_time": "2023-12-17T18:52:29.840202Z"
    }
   },
   "id": "caf97f2b1b17be22"
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [],
   "source": [
    "def get_dist(certain_list, candidate, fill_na=9999):\n",
    "    \"\"\"\n",
    "    Function calculating the distance between the full mention and a candidate.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    certain_list: list\n",
    "        List containing the already assigned entities.\n",
    "    candidate: float\n",
    "        Candidate id.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    distance: float\n",
    "        Distance between the full mention and the candidate.\n",
    "    \"\"\"\n",
    "    \n",
    "    distance_list = []\n",
    "    subset_certain = list(certain_list)\n",
    "    random.shuffle(subset_certain)\n",
    "    subset_size = 10\n",
    "    subset_certain = subset_certain[:subset_size]\n",
    "    \n",
    "    for assigned_entity in subset_certain:\n",
    "        try:\n",
    "            shortest = nx.shortest_path_length(G, source=assigned_entity, target=candidate)\n",
    "            distance_list.append(shortest)\n",
    "        except:\n",
    "            distance_list.append(fill_na)\n",
    "            \n",
    "    return sum(distance_list) / subset_size if distance_list else fill_na"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T19:34:14.051242Z",
     "start_time": "2023-12-17T19:34:14.024960Z"
    }
   },
   "id": "a769a09c2239499"
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [],
   "source": [
    "def get_all_dist(filtered_ls, full_mention_train):\n",
    "    \"\"\"\n",
    "    Function calculating the distance between the full mention and all the candidates.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filtered_ls: pd.DataFrame\n",
    "        DataFrame containing the candidates.\n",
    "    full_mention_train: list\n",
    "        List of the already assigned entities.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    distances: list\n",
    "        List containing the distances between the full mention and all the candidates.\n",
    "    \"\"\"\n",
    "    \n",
    "    distances = []\n",
    "    \n",
    "    for candidate_id, _, title in filtered_ls.iloc:\n",
    "        distances.append((title, candidate_id, get_dist(full_mention_train, candidate_id)))\n",
    "        \n",
    "    return distances"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T19:34:15.676615Z",
     "start_time": "2023-12-17T19:34:15.675533Z"
    }
   },
   "id": "b3d5f1e3fa796f46"
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "def get_info(current_document):\n",
    "    \"\"\"\n",
    "    Function retrieving the information from the current document.\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    current_document: list\n",
    "        List containing all the rows of the current document.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    found: pd.DataFrame\n",
    "        DataFrame containing the rows of the current document that have a link.\n",
    "    not_found: pd.DataFrame\n",
    "        DataFrame containing the rows of the current document that have to be assigned.\n",
    "    item_id_train: set\n",
    "        Set containing the ids of the entities that have a link.\n",
    "    full_mention_found: dict\n",
    "        Dictionary containing the full mentions that have a link and the corresponding link.\n",
    "    mention_test: set\n",
    "        Set containing the full mentions that have to be assigned.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(current_document):\n",
    "        document_df = pd.DataFrame(current_document)\n",
    "        full_mention_ = document_df[document_df['wiki_url'] != 'NOT_FOUND']\n",
    "        found = full_mention_[full_mention_['wiki_url'] != '?']\n",
    "        item_id_train = set(found.item_id.tolist())\n",
    "        full_mention_found = dict(zip(found['full_mention'].str.lower(), found['wiki_url']))\n",
    "\n",
    "        not_found = full_mention_[full_mention_['wiki_url'] == '?'].copy()\n",
    "        not_found.full_mention = not_found.full_mention.str.lower()\n",
    "        mention_test = set(not_found.full_mention.tolist())\n",
    "        \n",
    "        return found, not_found, item_id_train, full_mention_found, mention_test\n",
    "    \n",
    "    else:\n",
    "        return None, None, None, None, None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:52:31.516916Z",
     "start_time": "2023-12-17T18:52:31.511546Z"
    }
   },
   "id": "8cf28f991162537d"
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "def find_doc_range(df):\n",
    "    \"\"\"\n",
    "    Function returning a zipped tuple of end indexes and start indexes of documents.\n",
    "    \"\"\"\n",
    "    # TODO doc\n",
    "    def check_docstart(row):\n",
    "        \"\"\"\n",
    "        True if the current row is the row where the document starts.\n",
    "        \"\"\"\n",
    "        if pd.notnull(row['token']) and 'DOCSTART' in row['token']:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    data = df.copy()\n",
    "    data['docstart_id'] = df.apply(check_docstart, axis=1)\n",
    "    start_ids = data[data['docstart_id']]['id'].values\n",
    "    print(len(start_ids))\n",
    "    end_ids = start_ids[1:] - 1\n",
    "    end_ids = np.append(end_ids,len(df))\n",
    "    docs_range = zip(start_ids, end_ids)\n",
    "    \n",
    "    return docs_range"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:52:31.517064Z",
     "start_time": "2023-12-17T18:52:31.514603Z"
    }
   },
   "id": "67fa300bff9ad2e3"
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "def split_document_findings(document_dataframe):\n",
    "    \"\"\"\n",
    "    Function retrieving and separating entities depending on weather they are associated with a found url or not.\n",
    "    \"\"\"\n",
    "    #TODO doc.\n",
    "    document = document_dataframe[document_dataframe['wiki_url'] != 'NOT_FOUND']\n",
    "    found_links = document[document['wiki_url'] != '?']\n",
    "    not_found_links = document[document['wiki_url'] == '?']\n",
    "    return document, found_links, not_found_links"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:52:31.520076Z",
     "start_time": "2023-12-17T18:52:31.516790Z"
    }
   },
   "id": "39c20eb8f5859293"
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "def find_equal_string_candidates(mention, full_mention_found) -> list[str]:\n",
    "    #TODO doc.\n",
    "    candidate_urls = set()\n",
    "    for found_mention, url in full_mention_found.items():\n",
    "        if mention in found_mention:\n",
    "            candidate_urls.add(url)\n",
    "    return  list(candidate_urls)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:52:31.527924Z",
     "start_time": "2023-12-17T18:52:31.520739Z"
    }
   },
   "id": "42657415b7e35c00"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_substring_candidates(mention, saved_candidates):\n",
    "    #TODO make sure all dataframe have a lower case version for comparaison and use it.\n",
    "    #TODO doc.\n",
    "    if mention not in saved_candidates.keys(): \n",
    "        candidates = wiki_item.loc[lower_case_wiki_item_titles.contains(r'\\b{}\\b'.format(mention), na=False)]\n",
    "        saved_candidates[mention] = candidates\n",
    "        return candidates\n",
    "    else:\n",
    "        return saved_candidates[mention]\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a7fb74273865f75"
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "          item_id                 en_label          wikipedia_title\n0               1                 Universe                 Universe\n1               2                    Earth                    Earth\n2               3                     life                     Life\n3               4                    death                    Death\n4               5                    human                    Human\n...           ...                      ...                      ...\n5216231  77042017                  HR 4523                HD 102365\n5216232  77043280         Charlie Johnston        Charlie Johnstone\n5216233  77231860               Aldo Rossi    Aldo Rossi (musician)\n5216234  77240068  Ebenezer Baptist Church  Ebenezer Baptist Church\n5216235  77242291                New Court                New Court\n\n[5216236 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_id</th>\n      <th>en_label</th>\n      <th>wikipedia_title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Universe</td>\n      <td>Universe</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Earth</td>\n      <td>Earth</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>life</td>\n      <td>Life</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>death</td>\n      <td>Death</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>human</td>\n      <td>Human</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5216231</th>\n      <td>77042017</td>\n      <td>HR 4523</td>\n      <td>HD 102365</td>\n    </tr>\n    <tr>\n      <th>5216232</th>\n      <td>77043280</td>\n      <td>Charlie Johnston</td>\n      <td>Charlie Johnstone</td>\n    </tr>\n    <tr>\n      <th>5216233</th>\n      <td>77231860</td>\n      <td>Aldo Rossi</td>\n      <td>Aldo Rossi (musician)</td>\n    </tr>\n    <tr>\n      <th>5216234</th>\n      <td>77240068</td>\n      <td>Ebenezer Baptist Church</td>\n      <td>Ebenezer Baptist Church</td>\n    </tr>\n    <tr>\n      <th>5216235</th>\n      <td>77242291</td>\n      <td>New Court</td>\n      <td>New Court</td>\n    </tr>\n  </tbody>\n</table>\n<p>5216236 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_item"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:59:27.704434Z",
     "start_time": "2023-12-17T18:59:27.690015Z"
    }
   },
   "id": "1b36ab5cb4ac8313"
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "def title_to_wiki_url(title):\n",
    "    return URL + title.replace(' ', '_')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T19:01:30.883426Z",
     "start_time": "2023-12-17T19:01:30.870420Z"
    }
   },
   "id": "93c18a966273d5ad"
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [],
   "source": [
    "def find_best_candidate(candidate_df, found_ids):\n",
    "    \"\"\"\n",
    "    Function returning the best candidates for the mention.\n",
    "    \"\"\"\n",
    "    \n",
    "    distances = get_all_dist(candidate_df, found_ids)\n",
    "    obtained_distances = len(distances)\n",
    "    if obtained_distances == 1:\n",
    "        title, item_id, _ = distances[0]\n",
    "        return item_id, title_to_wiki_url(title)\n",
    "    elif obtained_distances >=1:\n",
    "        first_candidate, second_candidate = heapq.nsmallest(2, distances,key=lambda x: x[-1])  \n",
    "        if first_candidate[-1] < second_candidate[-1]:\n",
    "            title, item_id, _ = first_candidate\n",
    "            return item_id, title_to_wiki_url(title)\n",
    "    return np.nan, np.nan"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T19:34:23.614447Z",
     "start_time": "2023-12-17T19:34:23.601650Z"
    }
   },
   "id": "f32f033ad499a985"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the global constants and variables used for graph decisions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5d866ca71704049"
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "MAX_CANDIDATES = 50\n",
    "MAX_FETCHING_TRIES = 3\n",
    "SEED = 42\n",
    "OLD_SIZE = np.inf\n",
    "current_document = []\n",
    "saved_candidates = {}\n",
    "\n",
    "random.seed(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T19:53:45.594890Z",
     "start_time": "2023-12-17T19:53:45.577219Z"
    }
   },
   "id": "7036f038c34356b6"
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [],
   "source": [
    "testdf['full_mention'] = testdf['full_mention'].str.lower()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T19:53:47.355549Z",
     "start_time": "2023-12-17T19:53:47.353767Z"
    }
   },
   "id": "5859e944deadf52"
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [
    {
     "data": {
      "text/plain": "104343"
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testdf[~(testdf['wiki_url'] == '?')])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T19:53:47.366653Z",
     "start_time": "2023-12-17T19:53:47.359313Z"
    }
   },
   "id": "20ca1ab11b3d1a72"
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [
    {
     "data": {
      "text/plain": "            id                          token entity_tag full_mention  \\\n0            0  -DOCSTART- (947testa CRICKET)        NaN          NaN   \n1            1                        CRICKET        NaN          NaN   \n2            2                              -        NaN          NaN   \n4            4                           TAKE        NaN          NaN   \n5            5                           OVER        NaN          NaN   \n...        ...                            ...        ...          ...   \n104884  104884                        younger        NaN          NaN   \n104885  104885                        brother        NaN          NaN   \n104886  104886                              ,        NaN          NaN   \n104888  104888                              .        NaN          NaN   \n104889  104889                            NaN        NaN          NaN   \n\n         wiki_url en_redirect_title  item_id  \n0       NOT_FOUND               NaN      NaN  \n1       NOT_FOUND               NaN      NaN  \n2       NOT_FOUND               NaN      NaN  \n4       NOT_FOUND               NaN      NaN  \n5       NOT_FOUND               NaN      NaN  \n...           ...               ...      ...  \n104884  NOT_FOUND               NaN      NaN  \n104885  NOT_FOUND               NaN      NaN  \n104886  NOT_FOUND               NaN      NaN  \n104888  NOT_FOUND               NaN      NaN  \n104889  NOT_FOUND               NaN      NaN  \n\n[88175 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>token</th>\n      <th>entity_tag</th>\n      <th>full_mention</th>\n      <th>wiki_url</th>\n      <th>en_redirect_title</th>\n      <th>item_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-DOCSTART- (947testa CRICKET)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>CRICKET</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>-</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>TAKE</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>OVER</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>104884</th>\n      <td>104884</td>\n      <td>younger</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>104885</th>\n      <td>104885</td>\n      <td>brother</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>104886</th>\n      <td>104886</td>\n      <td>,</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>104888</th>\n      <td>104888</td>\n      <td>.</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>104889</th>\n      <td>104889</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>88175 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf[testdf.full_mention.isna()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T19:53:47.377065Z",
     "start_time": "2023-12-17T19:53:47.368832Z"
    }
   },
   "id": "d1bd3c886dc09d9f"
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [],
   "source": [
    "def find_within_doc_similarity(found_links, not_found_links):\n",
    "        #Shuffle mentions TODO check shuffle works and does not mess up the indexes\n",
    "        \n",
    "        #Series of list of string \n",
    "        candidates_urls = not_found_links['full_mention'].apply(lambda mention: find_equal_string_candidates(mention, dict(zip(found_links['full_mention'], found_links['wiki_url']))))\n",
    "        \n",
    "        len_candidates_urls = candidates_urls.apply(len)\n",
    "                \n",
    "        #for single candidates, retrieve the value and attribute it.\n",
    "        single_candidates = not_found_links[len_candidates_urls == 1]\n",
    "        single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n",
    "        \n",
    "        new_found_links = pd.concat([found_links, single_candidates])\n",
    "        new_not_found_links = not_found_links[len_candidates_urls != 1]\n",
    "    \n",
    "        return new_found_links, new_not_found_links"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T19:53:47.404847Z",
     "start_time": "2023-12-17T19:53:47.377487Z"
    }
   },
   "id": "8565d00bf04b5174"
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [],
   "source": [
    "def single_row_df_process(single_row_df):\n",
    "    row = single_row_df.iloc[0]\n",
    "    row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
    "    return row[['item_id', 'wiki_url']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T19:53:47.411708Z",
     "start_time": "2023-12-17T19:53:47.379724Z"
    }
   },
   "id": "36dadb9354188fe5"
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [],
   "source": [
    "def find_substring_similarity(found_links, not_found_links):\n",
    "    #try finding the best for substrings\n",
    "        candidates_df = not_found_links['full_mention'].apply(lambda mention: find_substring_candidates(mention, saved_candidates))\n",
    "        \n",
    "        # Calculate the number of candidates for each mention\n",
    "        df_len_per_candidates = candidates_df.apply(len)\n",
    "        \n",
    "        # All not found link that have a single candidate from dataframe.\n",
    "        single_candidates = not_found_links[df_len_per_candidates == 1]\n",
    "        #TODO check name of columns in candidates_df\n",
    "        candidates_df_with_one_row = candidates_df[df_len_per_candidates == 1]\n",
    "        if len(candidates_df_with_one_row) != 0:\n",
    "            single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
    "        new_found_links = pd.concat([found_links, single_candidates])\n",
    "        new_not_found_links = not_found_links[df_len_per_candidates != 1]\n",
    "        \n",
    "        \n",
    "        # Filter for multi candidates\n",
    "        multi_candidates = not_found_links[(df_len_per_candidates > 1) & (df_len_per_candidates <= MAX_CANDIDATES)]\n",
    "        multi_candidates_df = candidates_df[(df_len_per_candidates > 1) & (df_len_per_candidates <= MAX_CANDIDATES)]\n",
    "        # Apply find_best_candidate for each mention in multi_candidates\n",
    "        item_url_tuples = multi_candidates_df.apply(lambda df: find_best_candidate(df, new_found_links[~new_found_links['item_id'].isna()]['item_id']))\n",
    "        \n",
    "        try:\n",
    "            if len(item_url_tuples) !=0:\n",
    "                multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
    "        except:\n",
    "            display(multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series))\n",
    "            raise Exception\n",
    "                \n",
    "        new_not_found_links = new_not_found_links[~new_not_found_links['id'].isin(new_found_links['id'])]\n",
    "        new_found_links = pd.concat([found_links, multi_candidates])\n",
    "        return new_found_links, new_not_found_links\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T19:53:47.428027Z",
     "start_time": "2023-12-17T19:53:47.384776Z"
    }
   },
   "id": "a7799683a13c456b"
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                                126217\n",
      "en_label           Annemari Sandell-Hyvärinen\n",
      "wikipedia_title    Annemari Sandell-Hyvärinen\n",
      "Name: 100323, dtype: object\n",
      "item_id                       272669\n",
      "en_label           Jearl Miles Clark\n",
      "wikipedia_title    Jearl Miles Clark\n",
      "Name: 201934, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                             651988\n",
      "en_label           La Gazzetta dello Sport\n",
      "wikipedia_title    La Gazzetta dello Sport\n",
      "Name: 448889, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_found_links = pd.concat([found_links, multi_candidates])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                     2268915\n",
      "en_label           OSCE Minsk Group\n",
      "wikipedia_title    OSCE Minsk Group\n",
      "Name: 1123475, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_found_links = pd.concat([found_links, multi_candidates])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                   2366481\n",
      "en_label           Jed-Forest RFC\n",
      "wikipedia_title    Jed-Forest RFC\n",
      "Name: 1153761, dtype: object\n",
      "item_id                           20877353\n",
      "en_label           Watsonians Ladies Rugby\n",
      "wikipedia_title    Watsonians Ladies Rugby\n",
      "Name: 4548073, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                           3153884\n",
      "en_label           Inverness Thistle F.C.\n",
      "wikipedia_title    Inverness Thistle F.C.\n",
      "Name: 1407529, dtype: object\n",
      "item_id                           3153884\n",
      "en_label           Inverness Thistle F.C.\n",
      "wikipedia_title    Inverness Thistle F.C.\n",
      "Name: 1407529, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_found_links = pd.concat([found_links, multi_candidates])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                    50345205\n",
      "en_label           Zé Luis Oliveira\n",
      "wikipedia_title    Zé Luis Oliveira\n",
      "Name: 5085088, dtype: object\n",
      "item_id                    50345205\n",
      "en_label           Zé Luis Oliveira\n",
      "wikipedia_title    Zé Luis Oliveira\n",
      "Name: 5085088, dtype: object\n",
      "item_id                    50345205\n",
      "en_label           Zé Luis Oliveira\n",
      "wikipedia_title    Zé Luis Oliveira\n",
      "Name: 5085088, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_found_links = pd.concat([found_links, multi_candidates])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                  4170097\n",
      "en_label           Alla Dudayeva\n",
      "wikipedia_title    Alla Dudayeva\n",
      "Name: 1695550, dtype: object\n",
      "item_id                        245389\n",
      "en_label           Zygmunt Solorz-Żak\n",
      "wikipedia_title    Zygmunt Solorz-Żak\n",
      "Name: 182360, dtype: object\n",
      "item_id                           17425008\n",
      "en_label                    Anthony Barker\n",
      "wikipedia_title    Anthony Barker (priest)\n",
      "Name: 4300729, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_found_links = pd.concat([found_links, multi_candidates])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                          6660240\n",
      "en_label                    Liz McIntyre\n",
      "wikipedia_title    Liz McIntyre (writer)\n",
      "Name: 2873763, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_found_links = pd.concat([found_links, multi_candidates])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                    793740\n",
      "en_label           Bert Konterman\n",
      "wikipedia_title    Bert Konterman\n",
      "Name: 542989, dtype: object\n",
      "item_id                      202193\n",
      "en_label           Thomas Stickroth\n",
      "wikipedia_title    Thomas Stickroth\n",
      "Name: 155309, dtype: object\n",
      "item_id                  644323\n",
      "en_label           Dariusz Wosz\n",
      "wikipedia_title    Dariusz Wosz\n",
      "Name: 443430, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                             651988\n",
      "en_label           La Gazzetta dello Sport\n",
      "wikipedia_title    La Gazzetta dello Sport\n",
      "Name: 448889, dtype: object\n",
      "item_id                         8074392\n",
      "en_label                    Zoran Savic\n",
      "wikipedia_title    Zoran Savic (soccer)\n",
      "Name: 3680426, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_found_links = pd.concat([found_links, multi_candidates])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                                       5137416\n",
      "en_label           Co-Op Block and J. N. Ireland Bank\n",
      "wikipedia_title    Co-Op Block and J. N. Ireland Bank\n",
      "Name: 2164356, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                                 6248624\n",
      "en_label                     John Michael Gorst\n",
      "wikipedia_title    John Gorst (Hendon North MP)\n",
      "Name: 2704662, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                       3841280\n",
      "en_label           MFK Norilsk Nickel\n",
      "wikipedia_title    MFK Norilsk Nickel\n",
      "Name: 1627390, dtype: object\n",
      "item_id                                                       828392\n",
      "en_label           People's Party – Movement for a Democratic Slo...\n",
      "wikipedia_title    People's Party – Movement for a Democratic Slo...\n",
      "Name: 558727, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_found_links = pd.concat([found_links, multi_candidates])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                                    15694082\n",
      "en_label           1962 Rangoon University Protests\n",
      "wikipedia_title    1962 Rangoon University protests\n",
      "Name: 3988424, dtype: object\n",
      "item_id                      4671036\n",
      "en_label           The Sumitomo Bank\n",
      "wikipedia_title    The Sumitomo Bank\n",
      "Name: 1835208, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                          3128801\n",
      "en_label                       Hay Point\n",
      "wikipedia_title    Hay Point, Queensland\n",
      "Name: 1398970, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                        61569\n",
      "en_label           Martina Ertl-Renz\n",
      "wikipedia_title    Martina Ertl-Renz\n",
      "Name: 52205, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_found_links = pd.concat([found_links, multi_candidates])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                        61569\n",
      "en_label           Martina Ertl-Renz\n",
      "wikipedia_title    Martina Ertl-Renz\n",
      "Name: 52205, dtype: object\n",
      "item_id                        61569\n",
      "en_label           Martina Ertl-Renz\n",
      "wikipedia_title    Martina Ertl-Renz\n",
      "Name: 52205, dtype: object\n",
      "item_id                        61569\n",
      "en_label           Martina Ertl-Renz\n",
      "wikipedia_title    Martina Ertl-Renz\n",
      "Name: 52205, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_found_links = pd.concat([found_links, multi_candidates])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                           20877353\n",
      "en_label           Watsonians Ladies Rugby\n",
      "wikipedia_title    Watsonians Ladies Rugby\n",
      "Name: 4548073, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                  317417\n",
      "en_label           Ally McCoist\n",
      "wikipedia_title    Ally McCoist\n",
      "Name: 233253, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_found_links = pd.concat([found_links, multi_candidates])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                     239688\n",
      "en_label           Gianluca Vialli\n",
      "wikipedia_title    Gianluca Vialli\n",
      "Name: 178813, dtype: object\n",
      "item_id                        312148\n",
      "en_label            Andrei Kanchelsky\n",
      "wikipedia_title    Andrei Kanchelskis\n",
      "Name: 228847, dtype: object\n",
      "item_id                           3153884\n",
      "en_label           Inverness Thistle F.C.\n",
      "wikipedia_title    Inverness Thistle F.C.\n",
      "Name: 1407529, dtype: object\n",
      "item_id                           3153884\n",
      "en_label           Inverness Thistle F.C.\n",
      "wikipedia_title    Inverness Thistle F.C.\n",
      "Name: 1407529, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/861348272.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['wiki_url'] = candidates_urls[len_candidates_urls == 1].apply(lambda l: l[0])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2443426327.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['wiki_url'] = title_to_wiki_url(row['wikipedia_title'])\n",
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_candidates['item_id'], single_candidates['wiki_url'] = candidates_df_with_one_row.apply(single_row_df_process)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                6758902\n",
      "en_label           Marek Suker\n",
      "wikipedia_title    Marek Suker\n",
      "Name: 2917043, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_1821/2273143489.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi_candidates [['item_id', 'wiki_url']] = multi_candidates.index.to_series().map(item_url_tuples).apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "docs_range = find_doc_range(testdf)\n",
    "\n",
    "for start_ids, end_ids in docs_range:\n",
    "    \n",
    "    current_document = testdf.iloc[start_ids:end_ids]\n",
    "    # print(current_document)\n",
    "    #TODO make sure that everything is lowercase when comparing strings. IN ALL FUNCTIONS.\n",
    "    \n",
    "    # We are interested in the rows that should have a link\n",
    "    current_document, found_links, not_found_links = split_document_findings(current_document)\n",
    "    if len(not_found_links) == 0:\n",
    "        continue\n",
    "      \n",
    "    if len(found_links) == 0:\n",
    "        continue\n",
    "\n",
    "    found_links, not_found_links = find_within_doc_similarity(found_links, not_found_links)\n",
    "    if len(not_found_links) == 0:\n",
    "        testdf.update(found_links)\n",
    "        continue\n",
    "        \n",
    "    if len(found_links) == 0:\n",
    "        testdf.update(found_links)\n",
    "        continue\n",
    "        \n",
    "    found_links, not_found_links = find_substring_similarity(found_links, not_found_links)\n",
    "    testdf.update(found_links)\n",
    "\n",
    "# TODO re-concat not_found and found.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:12:24.777863Z",
     "start_time": "2023-12-17T20:11:27.640640Z"
    }
   },
   "id": "d7d41bff18135424"
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [
    {
     "data": {
      "text/plain": "            id                          token entity_tag    full_mention  \\\n0            0  -DOCSTART- (947testa CRICKET)        NaN             NaN   \n1            1                        CRICKET        NaN             NaN   \n2            2                              -        NaN             NaN   \n3            3                 LEICESTERSHIRE          B  leicestershire   \n4            4                           TAKE        NaN             NaN   \n...        ...                            ...        ...             ...   \n104885  104885                        brother        NaN             NaN   \n104886  104886                              ,        NaN             NaN   \n104887  104887                          Bobby          B           bobby   \n104888  104888                              .        NaN             NaN   \n104889  104889                            NaN        NaN             NaN   \n\n                                                 wiki_url en_redirect_title  \\\n0                                               NOT_FOUND               NaN   \n1                                               NOT_FOUND               NaN   \n2                                               NOT_FOUND               NaN   \n3       http://en.wikipedia.org/wiki/Leicestershire_Co...    LEICESTERSHIRE   \n4                                               NOT_FOUND               NaN   \n...                                                   ...               ...   \n104885                                          NOT_FOUND               NaN   \n104886                                          NOT_FOUND               NaN   \n104887                 http://en.wikipedia.org/wiki/Bobby             Bobby   \n104888                                          NOT_FOUND               NaN   \n104889                                          NOT_FOUND               NaN   \n\n          item_id  \n0             NaN  \n1             NaN  \n2             NaN  \n3       3229147.0  \n4             NaN  \n...           ...  \n104885        NaN  \n104886        NaN  \n104887   289262.0  \n104888        NaN  \n104889        NaN  \n\n[104890 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>token</th>\n      <th>entity_tag</th>\n      <th>full_mention</th>\n      <th>wiki_url</th>\n      <th>en_redirect_title</th>\n      <th>item_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-DOCSTART- (947testa CRICKET)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>CRICKET</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>-</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>LEICESTERSHIRE</td>\n      <td>B</td>\n      <td>leicestershire</td>\n      <td>http://en.wikipedia.org/wiki/Leicestershire_Co...</td>\n      <td>LEICESTERSHIRE</td>\n      <td>3229147.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>TAKE</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>104885</th>\n      <td>104885</td>\n      <td>brother</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>104886</th>\n      <td>104886</td>\n      <td>,</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>104887</th>\n      <td>104887</td>\n      <td>Bobby</td>\n      <td>B</td>\n      <td>bobby</td>\n      <td>http://en.wikipedia.org/wiki/Bobby</td>\n      <td>Bobby</td>\n      <td>289262.0</td>\n    </tr>\n    <tr>\n      <th>104888</th>\n      <td>104888</td>\n      <td>.</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>104889</th>\n      <td>104889</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NOT_FOUND</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>104890 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:13:04.042259Z",
     "start_time": "2023-12-17T20:13:04.026843Z"
    }
   },
   "id": "e8d39125e83f7134"
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [],
   "source": [
    "testdf.loc[:, 'wiki_url'] = testdf['wiki_url'].apply(lambda x: 'NOT_FOUND' if not (str(x).startswith('http')) else x)\n",
    "\n",
    "name = 'submission_new_1'\n",
    "testdf[['id', 'wiki_url']].to_csv(name + '.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:13:50.533522Z",
     "start_time": "2023-12-17T20:13:50.469968Z"
    }
   },
   "id": "bb82fc2a2d530089"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id = 1000\n",
    "MAX_CANDIDATES = 50\n",
    "OLD_SIZE = np.inf\n",
    "current_document = []\n",
    "saved_candidates = {}\n",
    "\n",
    "for index in tqdm(range(len(testdf)), desc=\"Processing\", total=len(testdf)):\n",
    "    row = testdf.iloc[index]\n",
    "    current_document.append({\n",
    "        'id': row['id'],\n",
    "        'token': row['token'],\n",
    "        'full_mention': row['en_redirect_title'],\n",
    "        'wiki_url': row['wiki_url'],\n",
    "        'item_id': row['item_id']\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        if row['token'].startswith('-DOCSTART-'):\n",
    "            document_df = pd.DataFrame(current_document)\n",
    "            current_document = []\n",
    "\n",
    "            full_mention_ = document_df[document_df['wiki_url'] != 'NOT_FOUND']\n",
    "            found = full_mention_[full_mention_['wiki_url'] != '?']\n",
    "            item_id_train = set(found.item_id.tolist())\n",
    "            full_mention_found = dict(zip(found['full_mention'].str.lower(), found['wiki_url']))\n",
    "\n",
    "            not_found = full_mention_[full_mention_['wiki_url'] == '?'].copy()\n",
    "            not_found.full_mention = not_found.full_mention.str.lower()\n",
    "            mention_test = set(not_found.full_mention.tolist())\n",
    "\n",
    "            old_size = OLD_SIZE\n",
    "            new_size = len(mention_test)\n",
    "            correct_links = []\n",
    "            for tries in range(3):\n",
    "                if new_size < old_size:\n",
    "                    random_order = list(mention_test)\n",
    "                    random.shuffle(random_order)\n",
    "\n",
    "                    for uncertain_word in (random_order):\n",
    "                        correct_link = None\n",
    "                        matching_urls = set(\n",
    "                            [url for mention, url in full_mention_found.items() if uncertain_word in mention])\n",
    "                        if len(matching_urls) == 1:  # if uncertain_word is a part of the correct entity\n",
    "                            full_mention_found[uncertain_word] = list(matching_urls)[0]\n",
    "                        elif len(matching_urls) > 1:\n",
    "                            print(uncertain_word, \"seems to belong to\", matching_urls)\n",
    "                        else:\n",
    "                            filtered_ls = wiki_item.loc[col_.contains(r'\\b{}\\b'.format(uncertain_word),na=False)] if uncertain_word not in saved_candidates.keys() else \\\n",
    "                            saved_candidates[uncertain_word]\n",
    "                            saved_candidates[uncertain_word] = filtered_ls\n",
    "                            no_candidates = len(filtered_ls)\n",
    "                            if not no_candidates:\n",
    "                                print(\"No match for\", uncertain_word)\n",
    "                            elif no_candidates == 1:\n",
    "                                full_mention_found[uncertain_word] = URL + \\\n",
    "                                                                     filtered_ls.wikipedia_title.tolist()[0].replace(\n",
    "                                                                         ' ', '_')\n",
    "                                item_id_train.add(filtered_ls.item_id.tolist()[0])\n",
    "                            elif no_candidates < MAX_CANDIDATES:\n",
    "                                distances = get_all_dist(filtered_ls, item_id_train)\n",
    "                                if len(distances) > 1:\n",
    "                                    first_candidate, second_candidate = heapq.nsmallest(2, distances,\n",
    "                                                                                        key=lambda x: x[-1])\n",
    "                                    if first_candidate[-1] < second_candidate[-1]:\n",
    "                                        title, choice, _ = first_candidate\n",
    "                                        full_mention_found[\n",
    "                                            uncertain_word] = URL + title.replace(' ', '_')\n",
    "                                        item_id_train.add(choice)\n",
    "                                    else:\n",
    "                                        print(\"can not decide between\", first_candidate, \"and\", second_candidate)\n",
    "                                else:\n",
    "                                    title, choice, _ = distances[0]\n",
    "                                    full_mention_found[\n",
    "                                        uncertain_word] = URL + title.replace(' ', '_')\n",
    "                                    item_id_train.add(choice)\n",
    "\n",
    "                            else:\n",
    "                                print(uncertain_word, \"has too many candidates\", no_candidates)\n",
    "                    old_size = len(mention_test)\n",
    "                    mention_test.difference_update(full_mention_found.keys())\n",
    "                    new_size = len(mention_test)\n",
    "            if len(not_found):\n",
    "                not_found.wiki_url = not_found.full_mention.map(full_mention_found)\n",
    "                not_found.to_csv(f'{CORRECTED_FOLDER}{id}.csv', index=False)\n",
    "                id += 1\n",
    "    except Exception as e:\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "763d11b49dbff51a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "partial = result_first_part\n",
    "testdf = test_df[['id', 'token', 'full_mention']]\n",
    "testdf = testdf.merge(partial, on='id')\n",
    "display(testdf)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cb917ad6d680791"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corrected_df = pd.DataFrame()\n",
    "counter = 0\n",
    "for i in range(100000):\n",
    "    try:\n",
    "        corrected_df = pd.concat([corrected_df, pd.read_csv(f'{CORRECTED_FOLDER}{i}.csv')[['id', 'wiki_url']]],\n",
    "                                 ignore_index=True)\n",
    "        counter += 1\n",
    "    except Exception as e:\n",
    "        pass\n",
    "corrected_df = corrected_df.drop_duplicates('id')\n",
    "counter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1b476e3b1144af7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df = pd.merge(testdf, corrected_df, on='id', how='left', suffixes=('_original', '_update'))\n",
    "\n",
    "merged_df['wiki_url'] = merged_df['wiki_url_update'].combine_first(merged_df['wiki_url_original'])\n",
    "\n",
    "merged_df = merged_df.drop(['wiki_url_original', 'wiki_url_update'], axis=1)\n",
    "print(len(merged_df[merged_df.wiki_url == '?']))\n",
    "merged_df.loc[merged_df['wiki_url'] == '?', 'wiki_url'] = 'NOT_FOUND'\n",
    "merged_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70e3fd5e0128c4a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df[['id', 'wiki_url']].to_csv(SUBMISSIONS_FOLDER + 'submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f42ed16e4c816fad"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
