{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import networkx as nx\n",
    "import heapq\n",
    "import random\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connection(only_train = False):\n",
    "    connection = pd.read_csv('statements.csv')\n",
    "    if only_train:\n",
    "        list_of_ids = pd.read_csv('train_wiki.csv') # obtain by running get_wiki.ipynb\n",
    "        list_of_ids = list_of_ids.item_id.tolist()\n",
    "        all_ids = set(connection['source_item_id'].unique()).union(set(connection['target_item_id'].unique()))\n",
    "\n",
    "        filtered_ids = set(list_of_ids).intersection(all_ids)\n",
    "\n",
    "        connection = connection[connection['source_item_id'].isin(filtered_ids) | connection['target_item_id'].isin(filtered_ids)]\n",
    "    return connection\n",
    "\n",
    "def add_edges(G,connection, progress= True):\n",
    "    if progress:\n",
    "        for source_item_id, _, target_item_id in tqdm(connection.iloc,total=len(connection)):\n",
    "            G.add_edge(source_item_id, target_item_id)\n",
    "    else:\n",
    "        G = nx.from_pandas_edgelist(list_of_ids, 'source_item_id', 'target_item_id', create_using=nx.Graph)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = get_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph() # Undirected Graph  //// Use DiGraph for directed graph\n",
    "G = add_edges(G, connection, progress = True) # progress = False is faster (use when submit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "\n",
    "print(f\"Number of nodes: {num_nodes}\")\n",
    "print(f\"Number of edges: {num_edges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_filename = \"graph_undirected_full.pkl\"\n",
    "\n",
    "# save graph pickle to the file\n",
    "with open(pickle_filename, 'wb') as pickle_file:\n",
    "    pickle.dump(G, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the filename for the pickle file\n",
    "pickle_filename = \"graph_undirected_full.pkl\"\n",
    "\n",
    "# Load the graph from the pickle file\n",
    "with open(pickle_filename, 'rb') as pickle_file:\n",
    "    G = pickle.load(pickle_file).to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>entity_tag</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wiki_url_x</th>\n",
       "      <th>wiki_url_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-DOCSTART- (947testa CRICKET)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CRICKET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LEICESTERSHIRE</td>\n",
       "      <td>B</td>\n",
       "      <td>LEICESTERSHIRE</td>\n",
       "      <td>?</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Leicestershire_Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104885</th>\n",
       "      <td>104885</td>\n",
       "      <td>brother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104886</th>\n",
       "      <td>104886</td>\n",
       "      <td>,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104887</th>\n",
       "      <td>104887</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>B</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>?</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Bobby_Timmons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104888</th>\n",
       "      <td>104888</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104889</th>\n",
       "      <td>104889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104890 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                          token entity_tag    full_mention  \\\n",
       "0            0  -DOCSTART- (947testa CRICKET)        NaN             NaN   \n",
       "1            1                        CRICKET        NaN             NaN   \n",
       "2            2                              -        NaN             NaN   \n",
       "3            3                 LEICESTERSHIRE          B  LEICESTERSHIRE   \n",
       "4            4                           TAKE        NaN             NaN   \n",
       "...        ...                            ...        ...             ...   \n",
       "104885  104885                        brother        NaN             NaN   \n",
       "104886  104886                              ,        NaN             NaN   \n",
       "104887  104887                          Bobby          B           Bobby   \n",
       "104888  104888                              .        NaN             NaN   \n",
       "104889  104889                            NaN        NaN             NaN   \n",
       "\n",
       "       wiki_url_x                                         wiki_url_y  \n",
       "0             NaN                                          NOT_FOUND  \n",
       "1             NaN                                          NOT_FOUND  \n",
       "2             NaN                                          NOT_FOUND  \n",
       "3               ?  http://en.wikipedia.org/wiki/Leicestershire_Co...  \n",
       "4             NaN                                          NOT_FOUND  \n",
       "...           ...                                                ...  \n",
       "104885        NaN                                          NOT_FOUND  \n",
       "104886        NaN                                          NOT_FOUND  \n",
       "104887          ?         http://en.wikipedia.org/wiki/Bobby_Timmons  \n",
       "104888        NaN                                          NOT_FOUND  \n",
       "104889        NaN                                          NOT_FOUND  \n",
       "\n",
       "[104890 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial = pd.read_csv('submission_train_aliases_uncertain.csv')\n",
    "testdf = pd.read_csv('test.csv')\n",
    "testdf = testdf.merge(partial, on='id')\n",
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>795</td>\n",
       "      <td>Universities in the United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975</td>\n",
       "      <td>Universities in the United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4396</td>\n",
       "      <td>David Barr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4402</td>\n",
       "      <td>Michael Sullivan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4552</td>\n",
       "      <td>United States Amateur Championships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>103998</td>\n",
       "      <td>Predrag Mijatović</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>104041</td>\n",
       "      <td>Predrag Mijatović</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>104124</td>\n",
       "      <td>Mijatović</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>104310</td>\n",
       "      <td>De Graafschap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>104877</td>\n",
       "      <td>1966 FIFA World Cup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                    1\n",
       "0       795   Universities in the United Kingdom\n",
       "1       975   Universities in the United Kingdom\n",
       "2      4396                           David Barr\n",
       "3      4402                     Michael Sullivan\n",
       "4      4552  United States Amateur Championships\n",
       "..      ...                                  ...\n",
       "351  103998                    Predrag Mijatović\n",
       "352  104041                    Predrag Mijatović\n",
       "353  104124                            Mijatović\n",
       "354  104310                        De Graafschap\n",
       "355  104877                  1966 FIFA World Cup\n",
       "\n",
       "[356 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redirect = pd.read_csv('enwiki_redirects.tsv', sep='\\t', header=None)\n",
    "temp = testdf[partial.wiki_url ==\"?\"].merge(redirect, left_on='full_mention', right_on=0)[['id',1]]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>entity_tag</th>\n",
       "      <th>wiki_url_y</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-DOCSTART- (947testa CRICKET)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CRICKET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LEICESTERSHIRE</td>\n",
       "      <td>B</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Leicestershire_Co...</td>\n",
       "      <td>LEICESTERSHIRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104885</th>\n",
       "      <td>104885</td>\n",
       "      <td>brother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104886</th>\n",
       "      <td>104886</td>\n",
       "      <td>,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104887</th>\n",
       "      <td>104887</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>B</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Bobby_Timmons</td>\n",
       "      <td>Bobby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104888</th>\n",
       "      <td>104888</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104889</th>\n",
       "      <td>104889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104890 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                          token entity_tag  \\\n",
       "0            0  -DOCSTART- (947testa CRICKET)        NaN   \n",
       "1            1                        CRICKET        NaN   \n",
       "2            2                              -        NaN   \n",
       "3            3                 LEICESTERSHIRE          B   \n",
       "4            4                           TAKE        NaN   \n",
       "...        ...                            ...        ...   \n",
       "104885  104885                        brother        NaN   \n",
       "104886  104886                              ,        NaN   \n",
       "104887  104887                          Bobby          B   \n",
       "104888  104888                              .        NaN   \n",
       "104889  104889                            NaN        NaN   \n",
       "\n",
       "                                               wiki_url_y               1  \n",
       "0                                               NOT_FOUND             NaN  \n",
       "1                                               NOT_FOUND             NaN  \n",
       "2                                               NOT_FOUND             NaN  \n",
       "3       http://en.wikipedia.org/wiki/Leicestershire_Co...  LEICESTERSHIRE  \n",
       "4                                               NOT_FOUND             NaN  \n",
       "...                                                   ...             ...  \n",
       "104885                                          NOT_FOUND             NaN  \n",
       "104886                                          NOT_FOUND             NaN  \n",
       "104887         http://en.wikipedia.org/wiki/Bobby_Timmons           Bobby  \n",
       "104888                                          NOT_FOUND             NaN  \n",
       "104889                                          NOT_FOUND             NaN  \n",
       "\n",
       "[104890 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = testdf.merge(temp, on='id', how='left')\n",
    "testdf[1] = testdf.apply(lambda row: row.full_mention if pd.isna(row[1]) else row[1], axis=1)\n",
    "\n",
    "testdf =  testdf.drop(columns=['wiki_url_x',  'full_mention'] )\n",
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>en_label</th>\n",
       "      <th>wikipedia_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Universe Universe</td>\n",
       "      <td>Universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Earth Earth</td>\n",
       "      <td>Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>life Life</td>\n",
       "      <td>Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>death Death</td>\n",
       "      <td>Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>human Human</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216231</th>\n",
       "      <td>77042017</td>\n",
       "      <td>HR 4523 HD 102365</td>\n",
       "      <td>HD 102365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216232</th>\n",
       "      <td>77043280</td>\n",
       "      <td>Charlie Johnston Charlie Johnstone</td>\n",
       "      <td>Charlie Johnstone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216233</th>\n",
       "      <td>77231860</td>\n",
       "      <td>Aldo Rossi Aldo Rossi (musician)</td>\n",
       "      <td>Aldo Rossi (musician)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216234</th>\n",
       "      <td>77240068</td>\n",
       "      <td>Ebenezer Baptist Church Ebenezer Baptist Church</td>\n",
       "      <td>Ebenezer Baptist Church</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216235</th>\n",
       "      <td>77242291</td>\n",
       "      <td>New Court New Court</td>\n",
       "      <td>New Court</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5216236 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          item_id                                         en_label  \\\n",
       "0               1                                Universe Universe   \n",
       "1               2                                      Earth Earth   \n",
       "2               3                                        life Life   \n",
       "3               4                                      death Death   \n",
       "4               5                                      human Human   \n",
       "...           ...                                              ...   \n",
       "5216231  77042017                                HR 4523 HD 102365   \n",
       "5216232  77043280               Charlie Johnston Charlie Johnstone   \n",
       "5216233  77231860                 Aldo Rossi Aldo Rossi (musician)   \n",
       "5216234  77240068  Ebenezer Baptist Church Ebenezer Baptist Church   \n",
       "5216235  77242291                              New Court New Court   \n",
       "\n",
       "                 wikipedia_title  \n",
       "0                       Universe  \n",
       "1                          Earth  \n",
       "2                           Life  \n",
       "3                          Death  \n",
       "4                          Human  \n",
       "...                          ...  \n",
       "5216231                HD 102365  \n",
       "5216232        Charlie Johnstone  \n",
       "5216233    Aldo Rossi (musician)  \n",
       "5216234  Ebenezer Baptist Church  \n",
       "5216235                New Court  \n",
       "\n",
       "[5216236 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_item = pd.read_csv('wiki_items.csv')[['item_id', 'en_label','wikipedia_title']]\n",
    "#wiki_item = wiki_item[wiki_item['item_id'].isin(filtered_ids)]\n",
    "\n",
    "wiki_item['en_label'] = wiki_item['en_label'] + \" \" + wiki_item['wikipedia_title']\n",
    "col_ = wiki_item.wikipedia_title.str.lower().str\n",
    "wiki_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>entity_tag</th>\n",
       "      <th>wiki_url_y</th>\n",
       "      <th>1</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-DOCSTART- (947testa CRICKET)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CRICKET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LEICESTERSHIRE</td>\n",
       "      <td>B</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Leicestershire_Co...</td>\n",
       "      <td>LEICESTERSHIRE</td>\n",
       "      <td>3229147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104885</th>\n",
       "      <td>104885</td>\n",
       "      <td>brother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104886</th>\n",
       "      <td>104886</td>\n",
       "      <td>,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104887</th>\n",
       "      <td>104887</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>B</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Bobby_Timmons</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>132341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104888</th>\n",
       "      <td>104888</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104889</th>\n",
       "      <td>104889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_FOUND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104890 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                          token entity_tag  \\\n",
       "0            0  -DOCSTART- (947testa CRICKET)        NaN   \n",
       "1            1                        CRICKET        NaN   \n",
       "2            2                              -        NaN   \n",
       "3            3                 LEICESTERSHIRE          B   \n",
       "4            4                           TAKE        NaN   \n",
       "...        ...                            ...        ...   \n",
       "104885  104885                        brother        NaN   \n",
       "104886  104886                              ,        NaN   \n",
       "104887  104887                          Bobby          B   \n",
       "104888  104888                              .        NaN   \n",
       "104889  104889                            NaN        NaN   \n",
       "\n",
       "                                               wiki_url_y               1  \\\n",
       "0                                               NOT_FOUND             NaN   \n",
       "1                                               NOT_FOUND             NaN   \n",
       "2                                               NOT_FOUND             NaN   \n",
       "3       http://en.wikipedia.org/wiki/Leicestershire_Co...  LEICESTERSHIRE   \n",
       "4                                               NOT_FOUND             NaN   \n",
       "...                                                   ...             ...   \n",
       "104885                                          NOT_FOUND             NaN   \n",
       "104886                                          NOT_FOUND             NaN   \n",
       "104887         http://en.wikipedia.org/wiki/Bobby_Timmons           Bobby   \n",
       "104888                                          NOT_FOUND             NaN   \n",
       "104889                                          NOT_FOUND             NaN   \n",
       "\n",
       "          item_id  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3       3229147.0  \n",
       "4             NaN  \n",
       "...           ...  \n",
       "104885        NaN  \n",
       "104886        NaN  \n",
       "104887   132341.0  \n",
       "104888        NaN  \n",
       "104889        NaN  \n",
       "\n",
       "[104890 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf['wiki_title'] = testdf.wiki_url_y.str[29:].str.replace('_', ' ')\n",
    "testdf = testdf.merge(wiki_item, left_on='wiki_title', right_on='wikipedia_title',how='left').drop(columns=['wikipedia_title','en_label', 'wiki_title'])\n",
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8ba093a162466fba5a81e13444ee84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/104890 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can not decicide between ('2015–16 Rayo Vallecano season', 20921826, 1.9) and ('2018–19 Rayo Vallecano season', 59655144, 1.9)\n",
      "oviedo has too much candidates 87\n",
      "zaragoza has too much candidates 128\n",
      "can not decicide between ('Extremadura UD', 994224, 2.0) and ('Canal Extremadura Televisión', 2935928, 2.0)\n",
      "can not decicide between ('Real Sociedad B', 1067750, 1.9) and ('1981–82 Real Sociedad season', 4580229, 1.9)\n",
      "tenerife has too much candidates 101\n",
      "can not decicide between ('Racing de Santander', 12236, 2.0) and ('2007–08 Racing de Santander season', 16824433, 2.0)\n",
      "can not decicide between ('Real Sociedad Gimnástica Española', 2479165, 2.0) and ('2009–10 Real Sociedad season', 4616132, 2.0)\n",
      "zaragoza has too much candidates 128\n",
      "can not decicide between ('2012–13 Rayo Vallecano season', 4628582, 1.9) and ('2014–15 Rayo Vallecano season', 17515428, 1.9)\n",
      "oviedo has too much candidates 87\n",
      "tenerife has too much candidates 101\n",
      "tenerife has too much candidates 101\n",
      "oviedo has too much candidates 87\n",
      "can not decicide between ('Real Sociedad Femenino', 5549552, 1.9) and ('1928–29 Real Sociedad season', 16822459, 1.9)\n",
      "zaragoza has too much candidates 128\n",
      "can not decicide between ('Rayo Vallecano', 10300, 2.0) and ('2000–01 Rayo Vallecano season', 16824003, 2.0)\n",
      "tenerife has too much candidates 101\n",
      "tenerife has too much candidates 101\n",
      "can not decicide between ('Dubravka Mijatović', 1562932, 2.7) and ('Čedomilj Mijatović', 8079697, 2.7)\n",
      "schulz has too much candidates 169\n",
      "national hockey league has too much candidates 89\n",
      "canucks has too much candidates 69\n",
      "can not decicide between ('Candace Cameron Bure', 235694, 2000.6) and ('Valeri Bure', 945734, 2000.6)\n",
      "vancouver canucks has too much candidates 58\n",
      "buffalo sabres has too much candidates 59\n",
      "vancouver canucks has too much candidates 58\n",
      "canucks has too much candidates 69\n",
      "national hockey league has too much candidates 89\n",
      "buffalo sabres has too much candidates 59\n",
      "canucks has too much candidates 69\n",
      "vancouver canucks has too much candidates 58\n",
      "buffalo sabres has too much candidates 59\n",
      "national hockey league has too much candidates 89\n",
      "No match for ny rangers\n",
      "national hockey league has too much candidates 89\n",
      "edmonton has too much candidates 878\n",
      "can not decicide between ('Carnegie Library (Anaheim, California)', 5043915, 1002.0) and (\"St. Michael's Episcopal Church (Anaheim, California)\", 7590691, 1002.0)\n",
      "edmonton has too much candidates 878\n",
      "No match for ny rangers\n",
      "No match for ny islanders\n",
      "tampa bay has too much candidates 215\n",
      "national hockey league has too much candidates 89\n",
      "anaheim has too much candidates 94\n",
      "golden state has too much candidates 83\n",
      "sacramento has too much candidates 436\n",
      "golden state has too much candidates 83\n",
      "sacramento has too much candidates 436\n",
      "afc asian cup has too much candidates 124\n",
      "asian cup has too much candidates 171\n",
      "asian cup has too much candidates 171\n",
      "afc asian cup has too much candidates 124\n",
      "No match for hapoel be'er sheva f.c.\n",
      "can not decicide between ('Maccabi Tel Aviv F.C.', 223728, 1.9) and ('Maccabi Tel Aviv B.C.', 819694, 1.9)\n",
      "No match for hapoel tzafririm holon f.c.\n",
      "can not decicide between ('Maccabi Tel Aviv F.C.', 223728, 1.9) and ('Maccabi Tel Aviv B.C.', 819694, 1.9)\n",
      "No match for hapoel tzafririm holon f.c.\n",
      "No match for hapoel be'er sheva f.c.\n",
      "koreans has too much candidates 51\n",
      "afc asian cup has too much candidates 124\n",
      "koreans has too much candidates 51\n",
      "afc asian cup has too much candidates 124\n",
      "sheffield shield has too much candidates 118\n",
      "can not decicide between ('Bellerive Oval', 1134044, 1.1) and ('List of international cricket centuries at Bellerive Oval', 6624173, 1.1)\n",
      "can not decicide between ('David Boon', 3017555, 1.1) and ('List of international cricket centuries by David Boon', 15131826, 1.1)\n",
      "No match for michael divenuto\n",
      "can not decicide between ('Bellerive Oval', 1134044, 1.1) and ('List of international cricket centuries at Bellerive Oval', 6624173, 1.1)\n",
      "sheffield shield has too much candidates 118\n",
      "can not decicide between ('David Boon', 3017555, 1.1) and ('List of international cricket centuries by David Boon', 15131826, 1.1)\n",
      "No match for michael divenuto\n",
      "sheffield shield has too much candidates 118\n",
      "No match for michael divenuto\n",
      "can not decicide between ('David Boon', 3017555, 1001.5) and ('List of international cricket centuries by David Boon', 15131826, 1001.5)\n",
      "can not decicide between ('Shane Warne', 555240, 1001.5) and ('List of international cricket five-wicket hauls by Shane Warne', 6624258, 1001.5)\n",
      "can not decicide between ('Bellerive Oval', 1134044, 1001.7) and ('List of international cricket centuries at Bellerive Oval', 6624173, 1001.7)\n",
      "sheffield shield has too much candidates 118\n",
      "can not decicide between ('David Boon', 3017555, 1001.7) and ('List of international cricket centuries by David Boon', 15131826, 1001.7)\n",
      "No match for michael divenuto\n",
      "can not decicide between ('Bellerive Oval', 1134044, 1001.7) and ('List of international cricket centuries at Bellerive Oval', 6624173, 1001.7)\n",
      "can not decicide between ('Shane Warne', 555240, 1001.7) and ('List of international cricket five-wicket hauls by Shane Warne', 6624258, 1001.7)\n",
      "No match for n.ireland\n",
      "No match for n.ireland\n",
      "premier league has too much candidates 1639\n",
      "can not decicide between ('Hednesford Town F.C.', 18293, 2.0) and ('Hednesford', 2132464, 2.0)\n",
      "can not decicide between ('Woking F.C.', 18528, 2.0) and ('Woking', 646225, 2.0)\n",
      "fa cup has too much candidates 601\n",
      "fa cup has too much candidates 601\n",
      "premier league has too much candidates 1639\n",
      "can not decicide between ('Woking F.C.', 18528, 2.0) and ('Woking', 646225, 2.0)\n",
      "can not decicide between ('Hednesford railway station', 2128872, 2.0) and ('Hednesford', 2132464, 2.0)\n",
      "No match for inverness thistle f.c.\n",
      "can not decicide between ('Hawick RFC', 930661, 2.0) and ('Hawick Burghs (UK Parliament constituency)', 5684762, 2.0)\n",
      "can not decicide between ('Huntly railway station', 2432464, 2.0) and ('Granville Gordon, 13th Marquess of Huntly', 5596900, 2.0)\n",
      "No match for elgin city f.c.\n",
      "can not decicide between ('Hawick', 407183, 2.0) and ('Hawick RFC', 930661, 2.0)\n",
      "No match for inverness thistle f.c.\n",
      "No match for elgin city f.c.\n",
      "can not decicide between ('Marquess of Huntly', 495961, 2.0) and ('Huntly', 1016931, 2.0)\n",
      "premier league has too much candidates 1639\n",
      "No match for inverness thistle f.c.\n",
      "can not decicide between ('Andy Sinton', 527691, 2.0) and ('Leigh Sinton', 6519675, 2.0)\n",
      "whelan has too much candidates 132\n",
      "holdsworth has too much candidates 50\n",
      "whelan has too much candidates 132\n",
      "holdsworth has too much candidates 50\n",
      "holdsworth has too much candidates 50\n",
      "whelan has too much candidates 132\n",
      "can not decicide between ('Saracen Cycles', 7421948, 2.7) and ('HMS Saracen (1831)', 55613225, 2.7)\n",
      "can not decicide between ('Saracen Cycles', 7421948, 2.7) and ('HMS Saracen (1831)', 55613225, 2.7)\n",
      "can not decicide between ('Guy Rowson', 5622570, 2.1) and ('Penny Rowson', 19661837, 2.1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUntitled-2.ipynb Cell 18\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#X24sdW50aXRsZWQ%3D?line=77'>78</a>\u001b[0m     \u001b[39mprint\u001b[39m(uncertain_word, \u001b[39m\"\u001b[39m\u001b[39mseems to belong to\u001b[39m\u001b[39m\"\u001b[39m, matching_urls)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#X24sdW50aXRsZWQ%3D?line=78'>79</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#X24sdW50aXRsZWQ%3D?line=79'>80</a>\u001b[0m     filtered_ls \u001b[39m=\u001b[39m wiki_item\u001b[39m.\u001b[39mloc[col_\u001b[39m.\u001b[39;49mcontains(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mb\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m\\\u001b[39;49m\u001b[39mb\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(uncertain_word), na\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)] \u001b[39mif\u001b[39;00m uncertain_word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m saved_candidates\u001b[39m.\u001b[39mkeys() \u001b[39melse\u001b[39;00m saved_candidates[uncertain_word]\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#X24sdW50aXRsZWQ%3D?line=80'>81</a>\u001b[0m     saved_candidates[uncertain_word] \u001b[39m=\u001b[39m filtered_ls\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#X24sdW50aXRsZWQ%3D?line=81'>82</a>\u001b[0m     no_candidates \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(filtered_ls)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/strings/accessor.py:129\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    125\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot use .str.\u001b[39m\u001b[39m{\u001b[39;00mfunc_name\u001b[39m}\u001b[39;00m\u001b[39m with values of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minferred dtype \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 129\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/strings/accessor.py:1260\u001b[0m, in \u001b[0;36mStringMethods.contains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[39mif\u001b[39;00m regex \u001b[39mand\u001b[39;00m re\u001b[39m.\u001b[39mcompile(pat)\u001b[39m.\u001b[39mgroups:\n\u001b[1;32m   1253\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1254\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis pattern is interpreted as a regular expression, and has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1255\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmatch groups. To actually get the groups, use str.extract.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1256\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m   1257\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1260\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data\u001b[39m.\u001b[39;49marray\u001b[39m.\u001b[39;49m_str_contains(pat, case, flags, na, regex)\n\u001b[1;32m   1261\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_result(result, fill_value\u001b[39m=\u001b[39mna, returns_string\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/strings/object_array.py:131\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_contains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m    129\u001b[0m         upper_pat \u001b[39m=\u001b[39m pat\u001b[39m.\u001b[39mupper()\n\u001b[1;32m    130\u001b[0m         f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: upper_pat \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mupper()\n\u001b[0;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_str_map(f, na, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mdtype(\u001b[39m\"\u001b[39;49m\u001b[39mbool\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/strings/object_array.py:71\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_map\u001b[0;34m(self, f, na_value, dtype, convert)\u001b[0m\n\u001b[1;32m     69\u001b[0m map_convert \u001b[39m=\u001b[39m convert \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(mask)\n\u001b[1;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     result \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer_mask(arr, f, mask\u001b[39m.\u001b[39;49mview(np\u001b[39m.\u001b[39;49muint8), map_convert)\n\u001b[1;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mAttributeError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m     73\u001b[0m     \u001b[39m# Reraise the exception if callable `f` got wrong number of args.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[39m# The user may want to be warned by this, instead of getting NaN\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     p_err \u001b[39m=\u001b[39m (\n\u001b[1;32m     76\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m((takes)|(missing)) (?(2)from \u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+ to )?\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+ \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(?(3)required )positional arguments?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2876\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/strings/object_array.py:124\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_contains.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    120\u001b[0m         flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mIGNORECASE\n\u001b[1;32m    122\u001b[0m     pat \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(pat, flags\u001b[39m=\u001b[39mflags)\n\u001b[0;32m--> 124\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: pat\u001b[39m.\u001b[39;49msearch(x) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m     \u001b[39mif\u001b[39;00m case:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_all_dist(filtered_ls, full_mention_train):\n",
    "    distances = []\n",
    "    for candidate, _,title in filtered_ls.iloc:\n",
    "        distances.append((title,candidate, get_dist(full_mention_train, candidate)))\n",
    "    return distances\n",
    "    \n",
    "def get_dist(certain_list, b, fill_na = 9999):\n",
    "    distance_list = []\n",
    "    subset_certain = list(certain_list)\n",
    "    random.shuffle(subset_certain)\n",
    "    subset_size = 10\n",
    "    subset_certain = subset_certain[:subset_size]\n",
    "    for a in subset_certain:\n",
    "        try:\n",
    "            shortest = nx.shortest_path_length(G, source=a, target=b)\n",
    "            distance_list.append(shortest)\n",
    "        except:\n",
    "            distance_list.append(fill_na)\n",
    "    return sum(distance_list)/subset_size if distance_list else fill_na\n",
    "\n",
    "def get_info(current_document):\n",
    "    if len(current_document):\n",
    "        document_df = pd.DataFrame(current_document)\n",
    "        full_mention_ = document_df[document_df['wiki_url'] != 'NOT_FOUND']\n",
    "        found = full_mention_[full_mention_['wiki_url'] != '?']\n",
    "        item_id_train = set(found.item_id.tolist()) \n",
    "        full_mention_found = dict(zip(found['full_mention'].str.lower(), found['wiki_url']))\n",
    "\n",
    "        not_found = full_mention_[full_mention_['wiki_url'] == '?'].copy()\n",
    "        not_found.full_mention = not_found.full_mention.str.lower()\n",
    "        mention_test = set(not_found.full_mention.tolist())\n",
    "        return found, not_found, item_id_train, full_mention_found, mention_test\n",
    "    else:\n",
    "        return None, None, None,None, None\n",
    "\n",
    "id=1000\n",
    "current_document = []\n",
    "saved_candidates = {}\n",
    "\n",
    "for index in tqdm(range(len(testdf)-1, -1, -1), desc=\"Processing\", total=len(testdf)):\n",
    "    row = testdf.iloc[index]\n",
    "    current_document.append({\n",
    "                    'id': row['id'],\n",
    "                    'token': row['token'],\n",
    "                    'full_mention': row[1],\n",
    "                    'wiki_url': row['wiki_url_y'], \n",
    "                    'item_id': row['item_id']\n",
    "                })\n",
    "    \n",
    "    try:\n",
    "        if row['token'].startswith('-DOCSTART-'):        \n",
    "            document_df = pd.DataFrame(current_document)\n",
    "            current_document = []\n",
    "\n",
    "            full_mention_ = document_df[document_df['wiki_url'] != 'NOT_FOUND']\n",
    "            found = full_mention_[full_mention_['wiki_url'] != '?']\n",
    "            item_id_train = set(found.item_id.tolist()) \n",
    "            full_mention_found = dict(zip(found['full_mention'].str.lower(), found['wiki_url']))\n",
    "\n",
    "            not_found = full_mention_[full_mention_['wiki_url'] == '?'].copy()\n",
    "            not_found.full_mention = not_found.full_mention.str.lower()\n",
    "            mention_test = set(not_found.full_mention.tolist())\n",
    "\n",
    "            old_size = 1000000\n",
    "            new_size = len(mention_test)\n",
    "            correct_links = []\n",
    "            for tries in range(3):\n",
    "                if new_size < old_size:\n",
    "                    random_order = list(mention_test)\n",
    "                    random.shuffle(random_order)\n",
    "                    \n",
    "                    for uncertain_word in (random_order):\n",
    "                        correct_link = None\n",
    "                        matching_urls = set([url for mention,url in full_mention_found.items() if uncertain_word in mention])\n",
    "                        if len(matching_urls)==1: #if uncertain_word is a part of the correct entity\n",
    "                            full_mention_found[uncertain_word] = list(matching_urls)[0]\n",
    "                        elif len(matching_urls)>1:\n",
    "                            print(uncertain_word, \"seems to belong to\", matching_urls)\n",
    "                        else:\n",
    "                            filtered_ls = wiki_item.loc[col_.contains(r'\\b{}\\b'.format(uncertain_word), na=False)] if uncertain_word not in saved_candidates.keys() else saved_candidates[uncertain_word]\n",
    "                            saved_candidates[uncertain_word] = filtered_ls\n",
    "                            no_candidates = len(filtered_ls)\n",
    "                            if not no_candidates:\n",
    "                                print(\"No match for\", uncertain_word)\n",
    "                            elif no_candidates == 1:\n",
    "                                full_mention_found[uncertain_word] = 'http://en.wikipedia.org/wiki/' + filtered_ls.wikipedia_title.tolist()[0].replace(' ','_')\n",
    "                                item_id_train.add(filtered_ls.item_id.tolist()[0]) \n",
    "                            elif no_candidates <  50:\n",
    "                                distances = get_all_dist(filtered_ls, item_id_train)\n",
    "                                if len(distances) > 1:\n",
    "                                    first_candidate, second_candidate = heapq.nsmallest(2, distances, key=lambda x: x[-1])\n",
    "                                    if first_candidate[-1] < second_candidate[-1]:\n",
    "                                        title, choice,_ = first_candidate\n",
    "                                        full_mention_found[uncertain_word] = 'http://en.wikipedia.org/wiki/' +title.replace(' ','_')\n",
    "                                        item_id_train.add(choice)\n",
    "                                    else:\n",
    "                                        print(\"can not decicide between\", first_candidate, \"and\", second_candidate)\n",
    "                                else:\n",
    "                                    title, choice,_ = distances[0]\n",
    "                                    full_mention_found[uncertain_word] = 'http://en.wikipedia.org/wiki/' +title.replace(' ','_')\n",
    "                                    item_id_train.add(choice)\n",
    "\n",
    "                            else: \n",
    "                                print(uncertain_word, \"has too much candidates\", no_candidates)\n",
    "                    old_size = len(mention_test)\n",
    "                    mention_test.difference_update(full_mention_found.keys())\n",
    "                    new_size = len(mention_test)\n",
    "            if len(not_found):\n",
    "                not_found.wiki_url = not_found.full_mention.map(full_mention_found)\n",
    "                not_found.to_csv(f'corrected/{id}.csv', index=False)\n",
    "                id +=1    \n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial = pd.read_csv('submission_train_aliases_uncertain.csv')\n",
    "testdf = pd.read_csv('test.csv')[['id', 'token', 'full_mention']]\n",
    "testdf = testdf.merge(partial, on='id')\n",
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_df = pd.DataFrame()\n",
    "counter = 0\n",
    "for i in range (100000):\n",
    "    try:\n",
    "        corrected_df = pd.concat([corrected_df, pd.read_csv(f'corrected/{i}.csv')[['id','wiki_url']]], ignore_index=True)\n",
    "        counter += 1\n",
    "    except Exception as e:\n",
    "        pass\n",
    "corrected_df = corrected_df.drop_duplicates('id')\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(testdf, corrected_df, on='id', how='left', suffixes=('_original', '_update'))\n",
    "\n",
    "merged_df['wiki_url'] = merged_df['wiki_url_update'].combine_first(merged_df['wiki_url_original'])\n",
    "\n",
    "merged_df = merged_df.drop(['wiki_url_original', 'wiki_url_update'], axis=1)\n",
    "print(len(merged_df[merged_df.wiki_url=='?']))\n",
    "merged_df.loc[merged_df['wiki_url'] == '?', 'wiki_url'] = 'NOT_FOUND'\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[['id', 'wiki_url']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
